# LLM 模型路由配置（草案）
# Phase 0 仅落文件，后续由运行时/Skills 读取并实现路由逻辑。

routing:
  casual_chat:
    primary: "ollama/llama3"
    fallback: "anthropic/claude-3-haiku"
    max_tokens: 500

  complex_reasoning:
    primary: "anthropic/claude-opus-4-5"
    max_tokens: 4000

  tool_learning:
    primary: "anthropic/claude-sonnet-4"
    max_tokens: 2000

  memory_summarization:
    primary: "anthropic/claude-3-haiku"
    max_tokens: 1000

  default:
    primary: "anthropic/claude-sonnet-4"
    max_tokens: 2000

